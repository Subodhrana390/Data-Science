{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc9e98b",
   "metadata": {},
   "source": [
    "## 📈 Linear Regression\n",
    "\n",
    "Linear Regression is a method used to model the relationship between a dependent variable `y` and an independent variable `x` by fitting a straight line.\n",
    "\n",
    "### ✅ Steps:\n",
    "\n",
    "**Step 1:** Find the pattern in the old (historical) data  \n",
    "**Step 2:** Fit a straight line through the data  \n",
    "**Step 3:** Use the line to make predictions\n",
    "\n",
    "### 🧮 Line Equation:\n",
    "\n",
    "\\[\n",
    "y = mx + b\n",
    "\\]\n",
    "\n",
    "- `y` = predicted value  \n",
    "- `m` = slope of the line  \n",
    "- `x` = input (independent variable)  \n",
    "- `b` = y-intercept (value of `y` when `x = 0`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0de6262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted marks: 874.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = [[1], [2], [3], [4], [5], [6]]\n",
    "y = [40, 50, 65, 75, 90, 100]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "hours = float(input(\"How many hours have you studied? \"))\n",
    "predict_marks = model.predict([[hours]])\n",
    "\n",
    "print(f\"Predicted marks: {predict_marks[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41a655c",
   "metadata": {},
   "source": [
    "## 🔐 Logistic Regression\n",
    "\n",
    "Logistic Regression is a classification algorithm used to predict **binary outcomes** (e.g., Yes/No, 0/1, Pass/Fail).\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Steps:\n",
    "\n",
    "**Step 1:** Collect labeled data (with class labels like 0 and 1)  \n",
    "**Step 2:** Find a pattern between inputs (X) and the binary output (y)  \n",
    "**Step 3:** Apply the logistic (sigmoid) function to map values between 0 and 1  \n",
    "**Step 4:** Predict the class based on a threshold (usually 0.5)\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 Logistic (Sigmoid) Function:\n",
    "\n",
    "\\[\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "\n",
    "- `z = mx + b` (similar to linear regression)\n",
    "- `σ(z)` = probability that output belongs to class 1\n",
    "- Output is always between **0 and 1**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 Prediction Rule:\n",
    "\n",
    "If  \n",
    "\\[\n",
    "\\sigma(z) \\geq 0.5 \\Rightarrow \\text{Class 1 (Positive)}\n",
    "\\]  \n",
    "Else  \n",
    "\\[\n",
    "\\sigma(z) < 0.5 \\Rightarrow \\text{Class 0 (Negative)}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Use Case Examples:\n",
    "\n",
    "- Spam detection (Spam or Not Spam)  \n",
    "- Disease diagnosis (Positive or Negative)  \n",
    "- Exam result (Pass or Fail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51404b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result: Fail\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = [[1], [2], [3], [4], [5], [6], [7], [8]]\n",
    "y = [0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "hours = float(input(\"How many hours have you studied? \"))\n",
    "predict_result = model.predict([[hours]])\n",
    "\n",
    "if predict_result[0] == 1:\n",
    "    print(\"Predicted result: Pass\")\n",
    "else:\n",
    "    print(\"Predicted result: Fail\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3281416",
   "metadata": {},
   "source": [
    "# 🧠 K-Nearest Neighbors (KNN) – Choosing `k = 2`\n",
    "\n",
    "In K-Nearest Neighbors (KNN), the `k` value represents the **number of nearest neighbors** used to classify a new data point.\n",
    "\n",
    "## 🔢 Why Choose `k = 2`?\n",
    "\n",
    "- With `k = 2`, the algorithm looks at the **2 closest neighbors** to a new input.\n",
    "- The predicted class is based on the **majority class** of these 2 neighbors.\n",
    "- It helps **reduce the impact of outliers** compared to `k = 1`.\n",
    "- Suitable when you want the model to be **slightly less sensitive** to noise than with `k = 1`, but still responsive to local patterns.\n",
    "\n",
    "## ⚠️ Considerations\n",
    "\n",
    "- `k = 2` can lead to **ties** (1 vote for each class), so many implementations break ties by:\n",
    "  - Picking the class with the **lower label** (e.g., `0` over `1`)\n",
    "  - Or **randomly selecting** between the tied classes\n",
    "- Small `k` values like 1 or 2 make the model **more flexible** but also more sensitive to noise.\n",
    "\n",
    "## ✅ When is `k = 2` a Good Choice?\n",
    "\n",
    "- When you have **balanced data**.\n",
    "- When the dataset is **small**, and you want a **quick, simple classifier**.\n",
    "- For **experimentation** or to observe how classification boundaries shift with different `k`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed673a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = [\n",
    "    [180, 7],\n",
    "    [200, 7.5],\n",
    "    [250, 8],\n",
    "    [300, 8.5],\n",
    "    [330, 9],\n",
    "    [360, 9.5]\n",
    "]\n",
    "\n",
    "y = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X, y)\n",
    "\n",
    "sample = [[320, 9]]\n",
    "prediction = model.predict(sample)\n",
    "\n",
    "print(f\"Predicted class: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e934e",
   "metadata": {},
   "source": [
    "# 🌳 Decision Tree Classifier – Understanding the Basics\n",
    "\n",
    "A **Decision Tree Classifier** is a supervised learning algorithm that splits the data into branches based on feature values, forming a tree-like structure to make decisions.\n",
    "\n",
    "## 🧠 Why Use a Decision Tree?\n",
    "\n",
    "- It is **easy to understand and interpret**.\n",
    "- Can handle both **numerical and categorical** data.\n",
    "- **No need for feature scaling**.\n",
    "- Works well for both **classification** and **regression** problems.\n",
    "\n",
    "## 🔍 How It Works\n",
    "\n",
    "- The model splits data by asking a series of **yes/no questions** (based on feature thresholds).\n",
    "- Each internal node represents a **decision rule**.\n",
    "- Each leaf node represents a **predicted class**.\n",
    "- The algorithm chooses splits that **maximize information gain** (or minimize impurity).\n",
    "\n",
    "## ⚠️ Considerations\n",
    "\n",
    "- Decision Trees can **overfit** if not properly controlled.\n",
    "- They are sensitive to **small changes in data**.\n",
    "- To improve performance:\n",
    "  - Set limits like `max_depth`, `min_samples_split`\n",
    "  - Use **pruning** or **ensemble methods** (like Random Forests)\n",
    "\n",
    "## ✅ When is a Decision Tree a Good Choice?\n",
    "\n",
    "- When you need a **model that is easy to explain** to non-technical stakeholders.\n",
    "- When **interpretability** is more important than raw accuracy.\n",
    "- When working with **tabular, structured data**.\n",
    "- When the dataset has **clear logical rules** or thresholds.\n",
    "\n",
    "## 🧾 Example Use Cases\n",
    "\n",
    "- Medical diagnosis (e.g., disease vs. no disease)\n",
    "- Customer segmentation (e.g., high value vs. low value)\n",
    "- Loan approval decisions (approve vs. reject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e77148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Features: [age, hours_of_sleep]\n",
    "X = [\n",
    "    [25, 8],   # young, sleeps well → tea\n",
    "    [30, 7],   # adult, normal sleep → tea\n",
    "    [45, 5],   # older, less sleep → coffee\n",
    "    [50, 4],   # older, little sleep → coffee\n",
    "]\n",
    "\n",
    "# Target labels: 0 = tea, 1 = coffee\n",
    "y = [0, 0, 1, 1]\n",
    "\n",
    "# Create and train the model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict for a new sample\n",
    "sample = [[50, 6]]  # middle-aged, moderate sleep\n",
    "prediction = model.predict(sample)\n",
    "\n",
    "print(f\"Predicted class: {prediction[0]}\")  # Output will be 0 (tea) or 1 (coffee)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
